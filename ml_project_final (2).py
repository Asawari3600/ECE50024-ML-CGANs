# -*- coding: utf-8 -*-
"""ML Project-Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TAEAHoOS7f3osgRZzUZTPrCjsBTTB9do

Asawari Walkade
MS ECE
(PUID: 0034291366)
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
# %matplotlib inline
import matplotlib.pyplot as plt

from keras.datasets import mnist
from keras.models import Sequential, Model
from keras.layers.convolutional import Conv2D, Conv2DTranspose
from keras.layers import Dense, LeakyReLU, BatchNormalization
from keras.layers import Input, Flatten, Embedding, multiply, Dropout
from keras.optimizers import Adam
from keras import initializers

model = Sequential()
(XTrain,LTrain), (XTest, LTest) = mnist.load_data()
YTrain = np.zeros((LTrain.shape[0], LTrain.max()+1), dtype=np.float32)
YTrain[np.arange(LTrain.shape[0]), LTrain] = 1
YTest = np.zeros((LTest.shape[0], LTest.max()+1), dtype=np.float32)
YTest[np.arange(LTest.shape[0]), LTest] = 1
input_array = np.arange(0, 10).reshape(1, -1)
model.compile(optimizer= 'sgd', loss='binary_crossentropy')
output_array = model.predict(input_array)
print(output_array)

fig = plt.figure()
for i in range(10):
    plt.subplot(1, 10, i+1)
    x_y = XTrain[LTrain == i]
    plt.imshow(x_y[0], cmap='gray', interpolation='none')
    plt.xticks([])
    plt.yticks([])
    
plt.tight_layout()

print('XTrain.shape', XTrain.shape)
print('LTrain.shape', LTrain.shape)
print('YTrain.shape', YTrain.shape)
# reshaping the inputs
XTrain = XTrain.reshape(60000, 28*28)
# normalizing the inputs (-1, 1)
XTrain = (XTrain.astype('float32') / 255 - 0.5) * 2
print('XTrain reshaped is:', XTrain.shape)

# latent space dimension
latent_dim = 75
img_dim = 784
init = initializers.RandomNormal(stddev=0.01)

# Generator network
generator = Sequential()

# Input layer and hidden layer 1
generator.add(Dense(128, input_shape=(latent_dim,), kernel_initializer=init))
generator.add(LeakyReLU(alpha=0.2))
generator.add(BatchNormalization(momentum=0.8))

# Hidden layer 2
generator.add(Dense(256))
generator.add(LeakyReLU(alpha=0.2))
generator.add(BatchNormalization(momentum=0.8))

# Hidden layer 3
generator.add(Dense(512))
generator.add(LeakyReLU(alpha=0.2))
generator.add(BatchNormalization(momentum=0.8))

#Hidden layer 4 (conv transpose layer)
model.add(Conv2DTranspose(128, (3, 3), strides=(1, 1), activation="relu"))

# Output layer 
generator.add(Dense(img_dim, activation='tanh'))

generator.summary()

# Embedding condition in input layer
num_classes = 10

# Create label embeddings
label = Input(shape=(1,), dtype='int32')
label_embedding = Embedding(num_classes, latent_dim)(label)
label_embedding = Flatten()(label_embedding)

# latent space
z = Input(shape=(latent_dim,))

# Merge inputs (z x label)
input_generator = multiply([z, label_embedding])

# Output image
img = generator(input_generator)

# Generator with condition input
generator = Model([z, label], img)

generator.summary()

# Discriminator network
discriminator = Sequential()

# Input layer and hidden layer 1
discriminator.add(Dense(128, input_shape=(img_dim,), kernel_initializer=init))
discriminator.add(LeakyReLU(alpha=0.2))

# Hidden layer 2
discriminator.add(Dense(256))
discriminator.add(LeakyReLU(alpha=0.2))

# Hidden layer 3
discriminator.add(Dense(512))
discriminator.add(LeakyReLU(alpha=0.2))

#Hidden layer 4 (conv layer)
model.add(Conv2D(128, (3, 3), strides=(1, 1), activation="relu"))

# Output layer
discriminator.add(Dense(1, activation='sigmoid'))

# prints a summary representation of your model
discriminator.summary()

# Embedding condition in input layer

# Create label embeddings
label_d = Input(shape=(1,), dtype='int32')
label_embedding_d = Embedding(num_classes, img_dim)(label_d)
label_embedding_d = Flatten()(label_embedding_d)

# imagem dimension 28x28
img_d = Input(shape=(img_dim,))

# Merge inputs (img x label)
input_discriminator = multiply([img_d, label_embedding_d])

# Output image
validity = discriminator(input_discriminator)

# Discriminator with condition input
discriminator = Model([img_d, label_d], validity)

# prints a summary representation of your model
discriminator.summary()

# Optimizer
#optimizer = Adam(lr=0.0002, beta_1=0.5)
discriminator.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['binary_accuracy'])

discriminator.trainable = False

validity = discriminator([generator([z, label]), label])

dis_gen = Model([z, label], validity)

dis_gen.compile(optimizer=Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy', metrics=['binary_accuracy'])

# prints a summary representation of your model
dis_gen.summary()

epochs = 200
batchsize = 64

valid = np.ones(shape=(batchsize, 1)) #array of ones, with col=1 created for "valid"
false = np.zeros(shape=(batchsize, 1)) #array of zeros, with col=1 created for "false"

dis_loss = [] #initializing the discriminator loss array
dis_gen_loss = [] #initializing the adversarial loss array

for epochs in range(epochs + 1):
    for i in range(len(XTrain) // batchsize):
        
        # Train Discriminator weights
        discriminator.trainable = True
        # Real samples
        XBatch = XTrain[i*batchsize:(i+1)*batchsize] 
        real_labels = LTrain[i*batchsize:(i+1)*batchsize].reshape(-1, 1)
        
        discriminator_loss_real = discriminator.train_on_batch(x=[XBatch, real_labels], y=valid) #the loss generated by valid sample pairs
        
        # Fake Samples
        z = np.random.normal(loc=0, scale=1, size=(batchsize, latent_dim))
        random_labels = np.random.randint(0, 10, batchsize).reshape(-1, 1)
        X_fake = generator.predict_on_batch([z, random_labels])
        
        discriminator_loss_fake = discriminator.train_on_batch(x=[X_fake, random_labels], y=false) #the loss generated by false sample pairs
         
        # Discriminator loss
        dis_loss_batch = (discriminator_loss_real[0] + discriminator_loss_fake[0]) #The total discriminator loss
        
        # Train Generator weights
        discriminator.trainable = False
        z = np.random.normal(loc=0, scale=1, size=(batchsize, latent_dim)) #random noise
        random_labels = np.random.randint(0, 10, batchsize).reshape(-1, 1)
        dis_gen_loss_batch = dis_gen.train_on_batch(x=[z, random_labels], y=valid) #This is the adversarial loss
   
        print('epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (epochs + 1, epochs, i, len(XTrain) // batchsize, dis_loss_batch, dis_gen_loss_batch[0]),100*' ',end='\r')
    
    dis_loss.append(dis_loss_batch)
    dis_gen_loss.append(dis_gen_loss_batch[0])
    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (epochs + 1, epochs, dis_loss[-1], dis_gen_loss[-1]), 100*' ')

    if epochs % 10 == 0: #taking a sample of 10 at a time
        samples = 10
        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))
        labels = np.arange(0, 10).reshape(-1, 1)
        x_fake = generator.predict([z, labels])

        for k in range(samples): #plotting images
            plt.subplot(2, 5, k+1)
            plt.imshow(x_fake[k].reshape(28, 28), cmap='gray')
            plt.xticks([])
            plt.yticks([])

        plt.tight_layout()
        plt.show()

# plotting the metrics
plt.plot(dis_gen_loss)
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Adversarial'], loc='center right')
plt.show()

